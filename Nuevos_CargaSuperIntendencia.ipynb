{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELDA 1: Configuración Inicial, Imports y Funciones\n",
    "# ===================================================================\n",
    "import pandas as pd\n",
    "import re\n",
    "from hubspot import HubSpot\n",
    "from hubspot.crm.properties import ApiException, PropertyUpdate, Option\n",
    "from rut_chile import rut_chile as rc\n",
    "import requests\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import concurrent.futures\n",
    "import sys\n",
    "\n",
    "# --- Archivo de Log ---\n",
    "log_file = open(\"log.txt\", \"w\")\n",
    "log_file.write(\"====================================================\\n\")\n",
    "log_file.write(\"== INICIO DEL SCRIPT: Nuevos Carga Superintendencia ==\\n\")\n",
    "log_file.write(\"====================================================\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "process = psutil.Process(os.getpid())\n",
    "mem_start = process.memory_info().rss\n",
    "\n",
    "# --- Funciones de Ayuda (Limpieza y Validación) ---\n",
    "def agregar_guion(valor):\n",
    "    if pd.notna(valor) and isinstance(valor, str) and len(valor) > 1:\n",
    "        return valor[:-1] + '-' + valor[-1]\n",
    "    return valor\n",
    "\n",
    "def eliminar_cero(valor):\n",
    "    if isinstance(valor, str) and valor.startswith('0'):\n",
    "        return valor[1:]\n",
    "    return valor\n",
    "\n",
    "def validar_rut(rut):\n",
    "    try:\n",
    "        return rc.is_valid_rut(rut)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def limpiar_valor(valor):\n",
    "    if not isinstance(valor, str):\n",
    "        return \"\"\n",
    "    valor_sin_tildes = unicodedata.normalize('NFKD', valor).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    valor_limpio = re.sub(r'[^\\w\\s]', '', valor_sin_tildes)\n",
    "    return valor_limpio.replace(' ', '_').lower()\n",
    "\n",
    "log_file.write(\"Funciones de ayuda definidas.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELDA 2: Conexión y Extracción de Datos de HubSpot\n",
    "# ===================================================================\n",
    "log_file.write(\"\\n--- Bloque 2: Extrayendo datos de HubSpot ---\\n\")\n",
    "df_final_contactos = pd.DataFrame()\n",
    "try:\n",
    "    log_file.write(\"Inicializando cliente de HubSpot...\\n\")\n",
    "    api_client = HubSpot(access_token=os.getenv('HUBSPOT_API_KEY'))\n",
    "    log_file.write(\"Cliente de HubSpot inicializado.\\n\")\n",
    "\n",
    "    properties = [ 'address','firstname','segundo_nombre', 'lastname','apellido_materno', 'condicion', 'createdate','crs',\n",
    "                'date_of_birth','direccion_de_trabajo','edad','email','estado_pago','fecha_inscripcion_al_colegio',\n",
    "    'fecha_titulo','gender','graduation_date','mobilephone','rcm','rut', 'lastmodifieddate', 'lifecyclestage',\n",
    "                  'phone','hs_object_source_label','especialidades','fecha_act_super']\n",
    "\n",
    "    log_file.write(f\"Recuperando contactos con {len(properties)} propiedades...\\n\")\n",
    "    all_contacts = api_client.crm.contacts.get_all(properties=properties)\n",
    "    contacts_list = [contact.to_dict() for contact in all_contacts]\n",
    "    log_file.write(f\"Se recuperaron {len(contacts_list)} contactos.\\n\")\n",
    "\n",
    "    df_contacts = pd.DataFrame(contacts_list)\n",
    "    df_col_dict = pd.json_normalize(df_contacts['properties'])\n",
    "    df_final_contactos = df_contacts.drop(columns=['properties']).join(df_col_dict)\n",
    "    df_final_contactos = df_final_contactos.sort_values(by=['createdate'], ascending = True)\n",
    "    log_file.write(\"DataFrames de HubSpot creados y procesados.\\n\")\n",
    "\n",
    "except ApiException as e:\n",
    "    log_file.write(f\"!!! ERROR al conectar con HubSpot: {e}\\n\")\n",
    "except Exception as e:\n",
    "    log_file.write(f\"!!! ERROR inesperado en el bloque 2: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELDA 3: Procesamiento de Datos de HubSpot y Filtrado de RUTs\n",
    "# ===================================================================\n",
    "lista_ruts = []\n",
    "df_ruts = pd.DataFrame()\n",
    "if not df_final_contactos.empty:\n",
    "    log_file.write(\"\\n--- Bloque 3: Procesando datos de HubSpot y filtrando RUTs ---\\n\")\n",
    "    df_final_contactos['rut_normalizado'] = (\n",
    "        df_final_contactos['rut'].astype(str).str.replace(r'[\\s.,-]', '', regex=True).apply(agregar_guion).apply(eliminar_cero))\n",
    "    df_final_contactos['rut_valido'] = df_final_contactos['rut_normalizado'].apply(validar_rut)\n",
    "    df_final_contactos['rut_sdv'] = df_final_contactos['rut_normalizado'].str.split('-').str[0]\n",
    "    \n",
    "    df_ruts = df_final_contactos[df_final_contactos['rut_valido']].copy()\n",
    "    df_ruts['fecha_act_super'] = pd.to_datetime(df_ruts['fecha_act_super'], errors='coerce')\n",
    "    \n",
    "    df_filtrado_rut = df_ruts[df_ruts['fecha_act_super'].isna()].copy()\n",
    "    lista_ruts = df_filtrado_rut['rut_sdv'].unique().tolist()\n",
    "    log_file.write(f\"Se preparó una lista de {len(lista_ruts)} RUTs para consultar en la API de la Superintendencia.\\n\")\n",
    "else:\n",
    "    log_file.write(\"\\n--- Bloque 3: Omitido por no haber datos de HubSpot ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELDA 4: Consulta a la API de la Superintendencia de Salud\n",
    "# ===================================================================\n",
    "log_file.write(\"\\n--- Bloque 4: Consultando API de la Superintendencia ---\\n\")\n",
    "df_resultados = pd.DataFrame()\n",
    "\n",
    "def consultar_api_super(rut):\n",
    "    url_base = \"https://apis.superdesalud.gob.cl/api/prestadores/rut/\"\n",
    "    apikey = os.getenv('SUPERDESALUD_API_KEY')\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\", \"Accept\": \"application/json\"}\n",
    "    url = f\"{url_base}{rut}.json/?apikey={apikey}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data and isinstance(data, list) and len(data) > 0:\n",
    "                data[0][\"rut_consultado\"] = rut\n",
    "                return data[0]\n",
    "        return None\n",
    "    except requests.RequestException as e:\n",
    "        log_file.write(f\"Error de conexión con RUT {rut}: {e}\\n\")\n",
    "        return None\n",
    "\n",
    "def obtener_datos_concurrente(ruts, max_workers=20):\n",
    "    resultados = []\n",
    "    if not ruts:\n",
    "        return pd.DataFrame()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(consultar_api_super, rut): rut for rut in ruts}\n",
    "        for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "            if (i + 1) % 20 == 0 or (i + 1) == len(ruts):\n",
    "                log_file.write(f\"Progreso de consulta: {i+1}/{len(ruts)} RUTs procesados\\n\")\n",
    "            resultado = future.result()\n",
    "            if resultado:\n",
    "                resultados.append(resultado)\n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "if lista_ruts:\n",
    "    df_resultados = obtener_datos_concurrente(lista_ruts, max_workers=20)\n",
    "    log_file.write(f\"Consulta a la Superintendencia finalizada. Se obtuvieron {len(df_resultados)} registros.\\n\")\n",
    "else:\n",
    "    log_file.write(\"No hay RUTs para consultar en la Superintendencia.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELDA 5: Procesamiento de Datos de la Superintendencia y Actualización de Opciones en HubSpot\n",
    "# ===================================================================\n",
    "if not df_resultados.empty:\n",
    "    log_file.write(\"\\n--- Bloque 5: Procesando datos y actualizando opciones en HubSpot ---\\n\")\n",
    "    \n",
    "    # CORRECCIÓN DEFINITIVA: Se verifica que las columnas 'rut' y 'dv' existan antes de usarlas.\n",
    "    if 'rut' in df_resultados.columns and 'dv' in df_resultados.columns:\n",
    "        df_resultados['rut_normalizado'] = df_resultados['rut'].astype(str) + '-' + df_resultados['dv'].astype(str)\n",
    "        \n",
    "        antecedentes_data = df_resultados[['rut_normalizado', 'antecedentes']]\n",
    "        antecedentes_desnormalizados = antecedentes_data.explode('antecedentes').reset_index(drop=True)\n",
    "        if 'antecedentes' in antecedentes_desnormalizados.columns and not antecedentes_desnormalizados['antecedentes'].isnull().all():\n",
    "            antecedentes_desnormalizados = pd.concat(\n",
    "                [antecedentes_desnormalizados.drop(['antecedentes'], axis=1), antecedentes_desnormalizados['antecedentes'].apply(pd.Series)],\n",
    "                axis=1)\n",
    "\n",
    "            # Lógica para actualizar las 3 propiedades (especialidades, universidad, nacionalidad)\n",
    "            for prop_info in [{'name': 'especialidades', 'source': antecedentes_desnormalizados[antecedentes_desnormalizados['clase_antecedente'] == 'Especialidad'], 'column': 'cod_antecedente'},\n",
    "                               {'name': 'universidad_titulo', 'source': antecedentes_desnormalizados[(antecedentes_desnormalizados['cod_antecedente'].isin(['Médica Cirujana', 'Médico Cirujano'])) & (antecedentes_desnormalizados['procedencia'] != 'EUNACOM')].drop_duplicates(subset='rut_normalizado', keep='first'), 'column': 'procedencia'},\n",
    "                               {'name': 'nacionalidad', 'source': df_resultados, 'column': 'nacionalidad'}]:\n",
    "                \n",
    "                try:\n",
    "                    property_name = prop_info['name']\n",
    "                    unique_values = prop_info['source'][prop_info['column']].dropna().unique()\n",
    "                    nuevas_opciones = [{\"label\": str(item).split(' -')[0], \"value\": limpiar_valor(str(item).split(' -')[0])} for item in sorted(unique_values) if str(item)]\n",
    "\n",
    "                    properties_api = api_client.crm.properties\n",
    "                    property_data = properties_api.core_api.get_by_name(object_type='contacts', property_name=property_name)\n",
    "                    current_options = property_data.options if property_data.options else []\n",
    "                    valores_existentes = {option.value for option in current_options}\n",
    "                    \n",
    "                    opciones_anadidas = 0\n",
    "                    for option in nuevas_opciones:\n",
    "                        if option['value'] not in valores_existentes:\n",
    "                            current_options.append(Option(label=option['label'], value=option['value']))\n",
    "                            valores_existentes.add(option['value'])\n",
    "                            opciones_anadidas += 1\n",
    "                    \n",
    "                    if opciones_anadidas > 0:\n",
    "                        log_file.write(f\"Agregando {opciones_anadidas} nuevas opciones a la propiedad '{property_name}'...\\n\")\n",
    "                        update_data = PropertyUpdate(options=current_options)\n",
    "                        properties_api.core_api.update(object_type='contacts', property_name=property_name, property_update=update_data)\n",
    "                        log_file.write(f\"Propiedad '{property_name}' actualizada con éxito.\\n\")\n",
    "                    else:\n",
    "                        log_file.write(f\"Propiedad '{property_name}' ya está al día.\\n\")\n",
    "                except Exception as e:\n",
    "                    log_file.write(f\"!!! ERROR al actualizar opciones de la propiedad '{property_name}': {e}\\n\")\n",
    "    else:\n",
    "        log_file.write(\"!!! ADVERTENCIA: Columnas 'rut' y/o 'dv' no se encontraron. Se omite el procesamiento de datos de la Superintendencia.\\n\")\n",
    "else:\n",
    "    log_file.write(\"No hay datos de la Superintendencia para procesar.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELDA 6: Actualización de Datos de Contactos en HubSpot\n",
    "# ===================================================================\n",
    "if not df_resultados.empty and 'rut_normalizado' in df_resultados.columns and not df_ruts.empty:\n",
    "    log_file.write(\"\\n--- Bloque 6: Actualizando datos de contactos en HubSpot ---\\n\")\n",
    "    try:\n",
    "        df_para_actualizar = pd.merge(df_resultados, df_ruts, on='rut_normalizado', how='inner')\n",
    "        df_para_actualizar = df_para_actualizar.loc[:, ~df_para_actualizar.columns.duplicated()]\n",
    "\n",
    "        total_a_actualizar = len(df_para_actualizar)\n",
    "        log_file.write(f\"Iniciando la actualización de {total_a_actualizar} contactos...\\n\")\n",
    "\n",
    "        for index, row in df_para_actualizar.iterrows():\n",
    "            contact_id = row['id']\n",
    "            fecha_nac_str = None\n",
    "            try:\n",
    "                fecha_nac_dt = pd.to_datetime(row.get('fecha_nacimiento'), format='%d/%m/%Y', errors='coerce')\n",
    "                if pd.notna(fecha_nac_dt):\n",
    "                    fecha_nac_str = fecha_nac_dt.strftime('%Y-%m-%d')\n",
    "            except Exception:\n",
    "                fecha_nac_str = None\n",
    "\n",
    "            data_to_update = {\n",
    "                'date_of_birth': fecha_nac_str,\n",
    "                'gender': row.get('sexo'),\n",
    "                'registro_superintendencia': row.get('nro_registro'),\n",
    "                'nacionalidad': limpiar_valor(row.get('nacionalidad_x')),\n",
    "                'firstname': row.get('nombres'),\n",
    "                'lastname': row.get('apellido_paterno_x'),\n",
    "                'apellido_materno': row.get('apellido_materno_x'),\n",
    "                'fecha_act_super': datetime.today().strftime('%Y-%m-%d')\n",
    "            }\n",
    "            \n",
    "            properties_payload = {k: v for k, v in data_to_update.items() if pd.notna(v)}\n",
    "            \n",
    "            url = f\"https://api.hubapi.com/crm/v3/objects/contacts/{contact_id}\"\n",
    "            headers = {'Authorization': f\"Bearer {os.getenv('HUBSPOT_API_KEY')}\", 'Content-Type': 'application/json'}\n",
    "            response = requests.patch(url, json={'properties': properties_payload}, headers=headers)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                log_file.write(f\"({index+1}/{total_a_actualizar}) Éxito: Contacto ID {contact_id} actualizado.\\n\")\n",
    "            else:\n",
    "                log_file.write(f\"!!! ERROR al actualizar contacto {contact_id}: {response.status_code} - {response.text}\\n\")\n",
    "    except Exception as e:\n",
    "        log_file.write(f\"!!! ERROR inesperado en el bloque 6: {e}\\n\")\n",
    "else:\n",
    "    log_file.write(\"\\n--- Bloque 6: Omitido por no haber datos para actualizar ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELDA FINAL: Cerrar el archivo de log\n",
    "# ===================================================================\n",
    "end_time = time.time()\n",
    "mem_end = process.memory_info().rss\n",
    "log_file.write(\"\\n====================================================\\n\")\n",
    "log_file.write(f\"== FIN DEL SCRIPT (Duración: {end_time - start_time:.2f} segundos) ==\\n\")\n",
    "log_file.write(f\"== Memoria usada: {(mem_end - mem_start) / (1024 * 1024):.2f} MB ==\\n\")\n",
    "log_file.write(\"====================================================\\n\")\n",
    "log_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}